{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8AvFrxTUlVoV"
      },
      "source": [
        "# Data Loading/Fetching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_DIR = Path.cwd()\n",
        "REPO_DIR = BASE_DIR / 'planet-understanding-the-amazon-from-space'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXjo7zxaIm8",
        "outputId": "150353ae-90b0-4500-ed0d-235b0acb57cb"
      },
      "outputs": [],
      "source": [
        "if not REPO_DIR.is_dir():\n",
        "    subprocess.run([\"kaggle datasets download paultimothymooney/open-elections-data-usa\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading planet-understanding-the-amazon-from-space.zip to /mnt/c/Users/bills/Desktop/Amazon_Rainforest\n",
            "100%|██████████████████████████████████████| 2.94M/2.94M [00:01<00:00, 3.21MB/s]\n",
            "100%|██████████████████████████████████████| 2.94M/2.94M [00:01<00:00, 2.94MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Expecting ~/.kaggle/kaggle.json to exist\n",
        "\n",
        "!kaggle competitions download -c \"planet-understanding-the-amazon-from-space\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxWAamDfaPkR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/planet-amazon-deforestation/img')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXUszhl0aUHf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoPhkDGkrMdv"
      },
      "source": [
        "Import into files \"train_v2.csv\", \"test_v2_file_mapping.csv\", \"sample_submission_v2.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZBzRu1QaUDu"
      },
      "outputs": [],
      "source": [
        "#paths from kaggle data\n",
        "train_path = '/content/train_v2.csv'\n",
        "test_path = '/content/test_v2_file_mapping.csv'\n",
        "sample_path = '/content/sample_submission_v2.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "d-nIxAK6aUAx",
        "outputId": "b75d67d6-82c2-40f1-f53d-0627fe22354c"
      },
      "outputs": [],
      "source": [
        "labels_tr_df = pd.read_csv(train_path)\n",
        "labels_tr_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JJNxiN0jaT-e",
        "outputId": "31559865-596e-4ee6-8a71-5affa7d07e28"
      },
      "outputs": [],
      "source": [
        "labels_tst_df = pd.read_csv(test_path)\n",
        "labels_tst_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw1AOZVQaT7-",
        "outputId": "3dd436b9-938b-4adc-84e5-6d63b429f974"
      },
      "outputs": [],
      "source": [
        "# Print all unique tags\n",
        "from itertools import chain\n",
        "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_tr_df['tags'].values]))\n",
        "labels_set = set(labels_list)\n",
        "print(\"There is {} unique labels including {}\".format(len(labels_set), labels_set))\n",
        "images_title = [labels_tr_df[labels_tr_df['tags'].str.contains(label)].iloc[i]['image_name'] + '.jpg'  for i, label in enumerate(labels_set)]\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Ptdlf5_RairA",
        "outputId": "945eff67-6236-403f-96a9-fbfb44ae6d03"
      },
      "outputs": [],
      "source": [
        "# Histogram of label instances\n",
        "labels_s = pd.Series(labels_list).value_counts() \n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "sns.barplot(x=labels_s, y=labels_s.index, orient='h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mennNpEgmiJp"
      },
      "source": [
        "As expected, some classes are largely representated whereas some are barely present in this dataset. There is a risk that our model barely learn the rare classes or even to exclude them from the training data upon splitting between training and validating sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ3GXdZqain9"
      },
      "outputs": [],
      "source": [
        "img_resize = (74, 74)  # nova velikost potrebna pro XCeption model\n",
        "validation_split_size = 0.2\n",
        "epochs = 20\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoekXmUXleU6"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXlWNGAUlg1z",
        "outputId": "f4172d4f-0372-4a00-9d84-95f4817fd403"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms as T, models\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "!pip install -q torchsummary --user\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qejD4AXcmmhv"
      },
      "source": [
        "##Class visualisation\n",
        "\n",
        "Let's now observe each label invidually. Each image is mapped to a list of labels, with a total of 17 different labels. All 17 labels are \"almost\" independent, meaning that primary can be found along with slash burn. I said \"almost\" because cloudy affects visibility, so that no other label can be found in the same image.\n",
        "\n",
        "For sake of clarity, I only displayed one label per image on the figure below. When images are associated to multiple labels, I displayed them multiple times (e.g. primary and haze)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WCdzz8Hr1Yf",
        "outputId": "1a44cd50-4dc4-41fa-9df9-fa82af0fdaa2"
      },
      "outputs": [],
      "source": [
        "!7z e train-jpg.tar.7z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C69wova39aaK",
        "outputId": "bc0331f0-2c01-48ef-cf73-7bc90425704b"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!7z x -so train-jpg.tar.7z | tar xf - -C /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd9QVRXD-Ud6"
      },
      "outputs": [],
      "source": [
        "path = \"/content/\"\n",
        "path_train_jpg = os.path.join(path, \"train-jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1tLXMhornNm9",
        "outputId": "9818d081-3b55-4d60-e958-cded9a57e595"
      },
      "outputs": [],
      "source": [
        "all_tags = list(set(labels_set))\n",
        "N_tags = len(all_tags)\n",
        "fig, axes = plt.subplots(4, (N_tags//4)+1, figsize=(20, 20))\n",
        "for idx, tag in enumerate(all_tags):\n",
        "    filename = labels_tr_df.loc[labels_tr_df.tags.str.contains(tag)].image_name.values[0]\n",
        "    img = cv2.imread(os.path.join(path_train_jpg, filename+\".jpg\"))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    idx_col = idx // 4\n",
        "    idx_row = idx % 4\n",
        "    axes[idx_row][idx_col].set_title(tag)\n",
        "    axes[idx_row][idx_col].imshow(img)\n",
        "axes[1][-1].remove()\n",
        "axes[2][-1].remove()\n",
        "axes[3][-1].remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF3cnyAn_p0w"
      },
      "source": [
        "We can make few remarks here:\n",
        "\n",
        "Some labels like \"water\" or \"road\" are challenging to differenciate\n",
        "Some rare labels like selecting logging and blooming are also hard to discriminate, and are barely visible at all\n",
        "Strong correlations can be expected between labels like habitation, road and cultivations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OQZZr-8HdaQ"
      },
      "source": [
        "##Transformations\n",
        "\n",
        "Resnet18 needs input shape that are multiple of 32 and in our case we have input of size 256. From 256, the closest multiple of 32 is 224.\n",
        "\n",
        "Therefore, we rescale our input data using this multiple, and we also normalize our dataset based on resnet pretrained mean and standard deviation intensity values. ToTensor() is useful to normalize our image values from 0-255 range to 0-1 range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNK3adLUJOox"
      },
      "outputs": [],
      "source": [
        "def get_transforms():\n",
        "    transform_train = T.Compose([\n",
        "      T.ToPILImage(),\n",
        "      T.Resize(224),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize(\n",
        "          mean=[0.485, 0.456, 0.406],\n",
        "          std=[0.229, 0.224, 0.225],\n",
        "      )\n",
        "    ])\n",
        "    transform_val = T.Compose([\n",
        "      T.ToPILImage(),\n",
        "      T.Resize(224),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "      )\n",
        "    ])\n",
        "    return transform_train, transform_val"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8ee81d84a34806034cf616698f38de3e99e4e7e40364b23dcb85d774b869f2c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
