{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Classification using Satellite Images and CNNs: Preprocessing, Analysis and Evaluation\n### By: Christian Tan_PH","metadata":{}},{"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This notebook provides an in-depth solution for training a machine learning model for image classification using satellite image chips with various land cover/land use and atmospheric conditions. <br> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It covers all essential stages such as data preparation, data analysis, model definition, training, evaluation and prediction. The code employs various libraries like numpy, pandas, matplotlib, tensorflow, keras, and scikit-learn to perform different tasks. The CNN architecture is used to train the model, which is a robust model for image classification tasks.<br><br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This code is perfect as a starting point for building similar models for image classification tasks and can be easily adapted to different datasets and requirements.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport os\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential \n\nimport keras as k\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n\nimport cv2\nfrom tqdm import tqdm\nfrom collections import Counter\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import fbeta_score\n\nimport plotly.express as px\nfrom tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n# set the matplotlib backend so figures can be saved in the background\nimport matplotlib\nmatplotlib.use(\"Agg\")\n# import the necessary packages\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import ToTensor\nfrom torchvision.datasets import KMNIST\nfrom torch.optim import Adam\nfrom torch import nn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport torch\nimport time\n# import the necessary packages\nfrom torch.nn import Module\nfrom torch.nn import Conv2d\nfrom torch.nn import Linear\nfrom torch.nn import MaxPool2d\nfrom torch.nn import ReLU\nfrom torch.nn import LogSoftmax\nfrom torch import flatten\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:39.347239Z","iopub.execute_input":"2023-02-23T14:24:39.347858Z","iopub.status.idle":"2023-02-23T14:24:57.748450Z","shell.execute_reply.started":"2023-02-23T14:24:39.347820Z","shell.execute_reply":"2023-02-23T14:24:57.747397Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading The Dataset","metadata":{}},{"cell_type":"code","source":"# Define the base path for the dataset\npath = \"../input/planets-dataset/planet/planet/\"\n\n# Join the base path with the train-jpg folder\npath_train = os.path.join(path, \"train-jpg\")\n\n# Join the base path with the test-jpg folder\npath_test = os.path.join(path, \"test-jpg\")\n\n# Use the os.listdir function to get the number of files in the train-jpg and test-jpg folders\nprint(\n    f\"train files: {len(os.listdir(path_train))}, \"\n    f\"test files: {len(os.listdir(path_test))}\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:57.750581Z","iopub.execute_input":"2023-02-23T14:24:57.750967Z","iopub.status.idle":"2023-02-23T14:24:58.925689Z","shell.execute_reply.started":"2023-02-23T14:24:57.750929Z","shell.execute_reply":"2023-02-23T14:24:58.924527Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train files: 40479, test files: 40669\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = os.path.join(path, \"train_classes.csv\")\nlabels_tr_df = pd.read_csv(train_path)\nlabels_tr_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:58.927620Z","iopub.execute_input":"2023-02-23T14:24:58.928027Z","iopub.status.idle":"2023-02-23T14:24:59.014950Z","shell.execute_reply.started":"2023-02-23T14:24:58.927988Z","shell.execute_reply":"2023-02-23T14:24:59.013860Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_path = os.path.join(path, \"train_classes.csv\")\nlabels_tst_df = pd.read_csv(test_path)\nlabels_tst_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:59.017996Z","iopub.execute_input":"2023-02-23T14:24:59.018663Z","iopub.status.idle":"2023-02-23T14:24:59.054745Z","shell.execute_reply.started":"2023-02-23T14:24:59.018622Z","shell.execute_reply":"2023-02-23T14:24:59.053653Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define the path to the train_classes.csv file\npath_train_class = os.path.join(path, \"train_classes.csv\")\n\n# Read the train_classes.csv file and store it in a DataFrame\ndf_train = pd.read_csv(path_train_class)\n\n# Print the shape of the DataFrame\nprint(df_train.shape)\n\n# Display the first 5 rows of the DataFrame\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:59.056517Z","iopub.execute_input":"2023-02-23T14:24:59.056910Z","iopub.status.idle":"2023-02-23T14:24:59.095453Z","shell.execute_reply.started":"2023-02-23T14:24:59.056874Z","shell.execute_reply":"2023-02-23T14:24:59.093400Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(40479, 2)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exploring and Understanding the Labels in the dataset","metadata":{}},{"cell_type":"code","source":"# Number Of Unique Tags In The Dataset\n# Avereage # Of Labels Per Image\n\nall_tags = [item for sublist in list(df_train['tags'].apply(lambda row: row.split(\" \")).values) for item in sublist]\nprint('total of {} non-unique tags in all training images'.format(len(all_tags)))\nprint('average number of labels per image {}'.format(1.0*len(all_tags)/df_train.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:59.096988Z","iopub.execute_input":"2023-02-23T14:24:59.097615Z","iopub.status.idle":"2023-02-23T14:24:59.146761Z","shell.execute_reply.started":"2023-02-23T14:24:59.097578Z","shell.execute_reply":"2023-02-23T14:24:59.145832Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"total of 116278 non-unique tags in all training images\naverage number of labels per image 2.8725511993873365\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label Distribution\n\n# Add a new column 'list_tags' to the DataFrame by splitting the 'tags' column on the space character\ndf_train[\"list_tags\"] = df_train.tags.str.split(\" \")\n\n# Get the values of the new column\nrow_tags = df_train.list_tags.values\n\n# Flatten the list of tags\ntags = [tag for row in row_tags for tag in row]\n\n# Count the occurrences of each tag\ncounter_tags = Counter(tags)\n\n# Create a new DataFrame with the tag and total columns\ndf_tags = pd.DataFrame(\n    {\"tag\": counter_tags.keys(), \"total\": counter_tags.values()}\n).sort_values(\"total\")\n\n# Create a bar chart of the tag distribution using Plotly\nfig = px.bar(df_tags, x=\"total\", y=\"tag\", orientation=\"h\", \n             color=\"total\",\n)\n\n# Update the chart title\nfig.update_layout(title=\"Tags distribution\")\n\n# Show the chart\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:24:59.148099Z","iopub.execute_input":"2023-02-23T14:24:59.148516Z","iopub.status.idle":"2023-02-23T14:25:01.303404Z","shell.execute_reply.started":"2023-02-23T14:24:59.148476Z","shell.execute_reply":"2023-02-23T14:25:01.302160Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"1779c6ac-c95e-40c1-8452-c0d9786f9e41\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1779c6ac-c95e-40c1-8452-c0d9786f9e41\")) {                    Plotly.newPlot(                        \"1779c6ac-c95e-40c1-8452-c0d9786f9e41\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"total=%{marker.color}<br>tag=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[100,101,209,332,339,340,862,2089,2697,3660,4547,7261,7411,8071,12315,28431,37513],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[100,101,209,332,339,340,862,2089,2697,3660,4547,7261,7411,8071,12315,28431,37513],\"xaxis\":\"x\",\"y\":[\"conventional_mine\",\"blow_down\",\"slash_burn\",\"blooming\",\"artisinal_mine\",\"selective_logging\",\"bare_ground\",\"cloudy\",\"haze\",\"habitation\",\"cultivation\",\"partly_cloudy\",\"water\",\"road\",\"agriculture\",\"clear\",\"primary\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"total\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"tag\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"total\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Tags distribution\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('1779c6ac-c95e-40c1-8452-c0d9786f9e41');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Machine Learning\n## Preparing the Data","metadata":{}},{"cell_type":"code","source":"# Drop the created \"list_tags\" column\n\ndf_train = df_train.drop(\"list_tags\", axis='columns')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:25:01.305044Z","iopub.execute_input":"2023-02-23T14:25:01.306670Z","iopub.status.idle":"2023-02-23T14:25:01.324001Z","shell.execute_reply.started":"2023-02-23T14:25:01.306625Z","shell.execute_reply":"2023-02-23T14:25:01.323038Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialization and Image Reading\n\n# Initialize empty lists to store the training images and their labels\nx_train = []\ny_train = []\n\n# Flatten the list of tags\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n\n# Create a label map for the unique tags in the dataset\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\n\n# Loop through the training DataFrame\nfor f, tags in tqdm(df_train.values, miniters=1000):\n    # Read the image file\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    # Initialize an array of zeros for the targets\n    targets = np.zeros(17)\n    # Loop through the tags for the current image\n    for t in tags.split(' '):\n        # Set the corresponding target value to 1\n        targets[label_map[t]] = 1 \n    # Append the image and its labels to the appropriate lists\n    x_train.append(cv2.resize(img, (64, 64)))  # Indicate the IMG Size\n    y_train.append(targets)\n\n# Convert the lists to numpy arrays\nx_train = np.array(x_train, np.float16) / 255.\ny_train = np.array(y_train, np.uint8)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:25:01.325565Z","iopub.execute_input":"2023-02-23T14:25:01.326229Z","iopub.status.idle":"2023-02-23T14:30:51.123699Z","shell.execute_reply.started":"2023-02-23T14:25:01.326188Z","shell.execute_reply":"2023-02-23T14:30:51.122560Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 40479/40479 [05:40<00:00, 118.73it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Converting the lists of images and labels to numpy arrays and normalizing the pixel values of the images. \ny_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float16) / 255.0\n\n# Splitting the data into train and validation sets. \nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\n# Prints the shape of the training and validation data.\nprint(\"Train data shape:\",x_train.shape)\nprint(\"Train label shape:\",y_train.shape)\n\nprint(\"Validation data shape:\",x_val.shape)\nprint(\"Validation label shape:\",y_val.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:51.128304Z","iopub.execute_input":"2023-02-23T14:30:51.128974Z","iopub.status.idle":"2023-02-23T14:30:57.869835Z","shell.execute_reply.started":"2023-02-23T14:30:51.128937Z","shell.execute_reply":"2023-02-23T14:30:57.868685Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train data shape: (32383, 64, 64, 3)\nTrain label shape: (32383, 17)\nValidation data shape: (8096, 64, 64, 3)\nValidation label shape: (8096, 17)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Free up some memory that is not being used by the program\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:57.871298Z","iopub.execute_input":"2023-02-23T14:30:57.872636Z","iopub.status.idle":"2023-02-23T14:30:58.122393Z","shell.execute_reply.started":"2023-02-23T14:30:57.872594Z","shell.execute_reply":"2023-02-23T14:30:58.121297Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"82"},"metadata":{}}]},{"cell_type":"markdown","source":"## Establishing Evaluation Metrics for the Model","metadata":{}},{"cell_type":"code","source":"# Defining a function that calculates the F-beta score for a given set of true labels and predicted labels.\n# The function balances precision and recall and it is useful when there is an imbalance in the number of positive and negative examples in the data.\n\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n\n    # Clipping y_pred between 0 and 1\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # Rounding y_pred to binary values\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    # Counting true positives, false positives, and false negatives\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n\n    # Calculating precision and recall\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:58.123798Z","iopub.execute_input":"2023-02-23T14:30:58.124529Z","iopub.status.idle":"2023-02-23T14:30:58.133937Z","shell.execute_reply.started":"2023-02-23T14:30:58.124488Z","shell.execute_reply":"2023-02-23T14:30:58.133023Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# This code defines a function that calculates the accuracy score for a given set of true labels and predicted labels.\ndef accuracy_score(y_true, y_pred, epsilon = 1e-4):\n    \n    # casting the true labels and predicted labels to float32\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    # counting the true positives\n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    \n    # counting the false positives\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    \n    # counting the false negatives\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    # casting the true labels and predicted labels to boolean\n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n    \n    # counting the true negatives\n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n                       axis = 1)\n    #calculating the accuracy score\n    return (tp + tn)/(tp + tn + fp + fn + epsilon)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:58.135537Z","iopub.execute_input":"2023-02-23T14:30:58.135910Z","iopub.status.idle":"2023-02-23T14:30:58.149946Z","shell.execute_reply.started":"2023-02-23T14:30:58.135875Z","shell.execute_reply":"2023-02-23T14:30:58.148816Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Constructing the Neural Network Architecture","metadata":{}},{"cell_type":"code","source":"# Importing different optimization algorithms from tensorflow.keras.optimizers\nfrom tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n\n# Instantiate the optimizer objects\noptimizer_Adam = Adam()\noptimizer_Adagrad = Adagrad()\noptimizer_RMSprop = RMSprop()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:58.151546Z","iopub.execute_input":"2023-02-23T14:30:58.151974Z","iopub.status.idle":"2023-02-23T14:30:58.175508Z","shell.execute_reply.started":"2023-02-23T14:30:58.151938Z","shell.execute_reply":"2023-02-23T14:30:58.174349Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define The Model\nmodel = keras.Sequential()\n\n# Adding The Layers\n# Batch Normalization layer is added as the first layer of the model, which normalize the input data.\nmodel.add(BatchNormalization(input_shape=(64, 64, 3)))\n\n# Convolutional layers and MaxPooling layers are added to extract features from the input images and reduce the spatial dimensions of the feature maps respectively.\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Dropout layers are added to prevent overfitting.\nmodel.add(Dropout(0.2))\n\n# Same set of layers are added for the next set of features\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Flatten layer is added to convert the 2D feature maps into a 1D feature vector\nmodel.add(Flatten())\n\n# Fully connected layers (dense layers) and dropout layers are added\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(17, activation='sigmoid'))\n\n# Compiling the model by specifying the loss function, optimizer, and evaluation metrics\nmodel.compile(optimizer=optimizer_Adam,\n              loss='binary_crossentropy',\n              metrics=[fbeta, accuracy_score])\n\n# Training the model on the training data for 10 epoch with a batch size of 128, and validating the model on the validation data\nhistory = model.fit(x_train, y_train,\n                      batch_size=128,\n                      epochs=10,\n                      verbose=1,\n                      validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:30:58.176728Z","iopub.execute_input":"2023-02-23T14:30:58.177546Z","iopub.status.idle":"2023-02-23T14:33:01.479326Z","shell.execute_reply.started":"2023-02-23T14:30:58.177508Z","shell.execute_reply":"2023-02-23T14:33:01.478143Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n253/253 [==============================] - 25s 44ms/step - loss: 0.2298 - fbeta: 0.6431 - accuracy_score: 0.9125 - val_loss: 0.3110 - val_fbeta: 0.6111 - val_accuracy_score: 0.9065\nEpoch 2/10\n253/253 [==============================] - 9s 36ms/step - loss: 0.1821 - fbeta: 0.7215 - accuracy_score: 0.9283 - val_loss: 0.2491 - val_fbeta: 0.6410 - val_accuracy_score: 0.9135\nEpoch 3/10\n253/253 [==============================] - 9s 36ms/step - loss: 0.1649 - fbeta: 0.7505 - accuracy_score: 0.9352 - val_loss: 0.1582 - val_fbeta: 0.7639 - val_accuracy_score: 0.9385\nEpoch 4/10\n253/253 [==============================] - 9s 36ms/step - loss: 0.1549 - fbeta: 0.7660 - accuracy_score: 0.9391 - val_loss: 0.1506 - val_fbeta: 0.7910 - val_accuracy_score: 0.9407\nEpoch 5/10\n253/253 [==============================] - 9s 36ms/step - loss: 0.1491 - fbeta: 0.7754 - accuracy_score: 0.9416 - val_loss: 0.1432 - val_fbeta: 0.7855 - val_accuracy_score: 0.9436\nEpoch 6/10\n253/253 [==============================] - 9s 37ms/step - loss: 0.1438 - fbeta: 0.7836 - accuracy_score: 0.9433 - val_loss: 0.1436 - val_fbeta: 0.7928 - val_accuracy_score: 0.9433\nEpoch 7/10\n253/253 [==============================] - 9s 37ms/step - loss: 0.1388 - fbeta: 0.7909 - accuracy_score: 0.9452 - val_loss: 0.1369 - val_fbeta: 0.8080 - val_accuracy_score: 0.9450\nEpoch 8/10\n253/253 [==============================] - 9s 37ms/step - loss: 0.1337 - fbeta: 0.7993 - accuracy_score: 0.9469 - val_loss: 0.1365 - val_fbeta: 0.8064 - val_accuracy_score: 0.9460\nEpoch 9/10\n253/253 [==============================] - 9s 37ms/step - loss: 0.1297 - fbeta: 0.8053 - accuracy_score: 0.9481 - val_loss: 0.1304 - val_fbeta: 0.8098 - val_accuracy_score: 0.9485\nEpoch 10/10\n253/253 [==============================] - 9s 37ms/step - loss: 0.1250 - fbeta: 0.8121 - accuracy_score: 0.9496 - val_loss: 0.1272 - val_fbeta: 0.8157 - val_accuracy_score: 0.9497\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:01.481259Z","iopub.execute_input":"2023-02-23T14:33:01.482206Z","iopub.status.idle":"2023-02-23T14:33:01.491797Z","shell.execute_reply.started":"2023-02-23T14:33:01.482158Z","shell.execute_reply":"2023-02-23T14:33:01.489450Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization (BatchNo (None, 64, 64, 3)         12        \n_________________________________________________________________\nconv2d (Conv2D)              (None, 64, 64, 32)        896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 62, 62, 32)        9248      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 31, 31, 64)        18496     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 29, 29, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 14, 14, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 12544)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               6423040   \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 17)                8721      \n=================================================================\nTotal params: 6,497,341\nTrainable params: 6,497,335\nNon-trainable params: 6\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(history.history['loss'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:01.493077Z","iopub.execute_input":"2023-02-23T14:33:01.493534Z","iopub.status.idle":"2023-02-23T14:33:01.634458Z","shell.execute_reply.started":"2023-02-23T14:33:01.493490Z","shell.execute_reply":"2023-02-23T14:33:01.632924Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\n# Adding title, y-label and x-label to the plot\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\n\n# Adding legend to the plot\nplt.legend(['train', 'validation'], loc='upper left')\n\n# Showing the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:01.635980Z","iopub.execute_input":"2023-02-23T14:33:01.636642Z","iopub.status.idle":"2023-02-23T14:33:01.702726Z","shell.execute_reply.started":"2023-02-23T14:33:01.636601Z","shell.execute_reply":"2023-02-23T14:33:01.701616Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nmodel.evaluate(x_val, y_val)\n\n# Calculate the f-beta score for the training set\ntrain_fscore = fbeta_score(y_train, np.round(model.predict(x_train)), beta=2,average = 'weighted')\nprint(\"train fscore: \", train_fscore)\n\n# Calculate the f-beta score for the validation set\nval_fscore = fbeta_score(y_val, np.round(model.predict(x_val)), beta=2, average = 'weighted')\nprint(\"val fscore: \", val_fscore)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:01.704592Z","iopub.execute_input":"2023-02-23T14:33:01.704987Z","iopub.status.idle":"2023-02-23T14:33:13.628087Z","shell.execute_reply.started":"2023-02-23T14:33:01.704948Z","shell.execute_reply":"2023-02-23T14:33:13.626898Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"253/253 [==============================] - 1s 4ms/step - loss: 0.1272 - fbeta: 0.8157 - accuracy_score: 0.9497\ntrain fscore:  0.8189473104612389\nval fscore:  0.8021128620500748\n","output_type":"stream"}]},{"cell_type":"code","source":"class myCNN(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 8, kernel_size=1, stride=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(8, 16, kernel_size=1, stride=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 7 * 7, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, 17),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 7 * 7)\n        x = self.classifier(x)\n        return torch.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:13.629956Z","iopub.execute_input":"2023-02-23T14:33:13.630354Z","iopub.status.idle":"2023-02-23T14:33:13.644184Z","shell.execute_reply.started":"2023-02-23T14:33:13.630316Z","shell.execute_reply":"2023-02-23T14:33:13.643168Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# define training hyperparameters\nINIT_LR = 1e-3\nBATCH_SIZE = 64\nEPOCHS = 10\n# define the train and val splits\nTRAIN_SPLIT = 0.75\nVAL_SPLIT = 1 - TRAIN_SPLIT\n# set the device we will be using to train the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:13.645737Z","iopub.execute_input":"2023-02-23T14:33:13.647648Z","iopub.status.idle":"2023-02-23T14:33:13.676210Z","shell.execute_reply.started":"2023-02-23T14:33:13.647605Z","shell.execute_reply":"2023-02-23T14:33:13.675110Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# initialize the train, validation, and test data loaders\ntrainDataLoader = DataLoader(df_train, shuffle=True,batch_size=BATCH_SIZE)\n#valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n#testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n# calculate steps per epoch for training and validation set\ntrainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n#valSteps = len(valDataLoader.dataset) // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:13.678048Z","iopub.execute_input":"2023-02-23T14:33:13.678568Z","iopub.status.idle":"2023-02-23T14:33:13.697645Z","shell.execute_reply.started":"2023-02-23T14:33:13.678530Z","shell.execute_reply":"2023-02-23T14:33:13.696532Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainDataLoader","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:13.699417Z","iopub.execute_input":"2023-02-23T14:33:13.699868Z","iopub.status.idle":"2023-02-23T14:33:13.714251Z","shell.execute_reply.started":"2023-02-23T14:33:13.699828Z","shell.execute_reply":"2023-02-23T14:33:13.713210Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7efbe06cec10>"},"metadata":{}}]},{"cell_type":"code","source":"# initialize the LeNet model\nprint(\"[INFO] initializing the LeNet model...\")\nmodel_nn = myCNN().to(device)\n# initialize our optimizer and loss function\nopt = Adam(model_nn.parameters(), lr=INIT_LR)\nlossFn = nn.CrossEntropyLoss()\n# initialize a dictionary to store training history\nH = {\n\t\"train_loss\": [],\n\t\"train_acc\": [],\n\t\"val_loss\": [],\n\t\"val_acc\": []\n}\n# measure how long training is going to take\nprint(\"[INFO] training the network...\")\nstartTime = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:13.715585Z","iopub.execute_input":"2023-02-23T14:33:13.715919Z","iopub.status.idle":"2023-02-23T14:33:14.064666Z","shell.execute_reply.started":"2023-02-23T14:33:13.715892Z","shell.execute_reply":"2023-02-23T14:33:14.063562Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[INFO] initializing the LeNet model...\n[INFO] training the network...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n \n  def __init__(self,file_name):\n    price_df=pd.read_csv(file_name)\n \n    x=x_train # get older previous process and add it here\n    y=y_train\n \n    self.x_train=torch.tensor(x,dtype=torch.float32)\n    self.y_train=torch.tensor(y,dtype=torch.float32)\n \n  def __len__(self):\n    return len(self.y_train)\n   \n  def __getitem__(self,idx):\n    return self.x_train[idx],self.y_train[idx]","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:14.066233Z","iopub.execute_input":"2023-02-23T14:33:14.067156Z","iopub.status.idle":"2023-02-23T14:33:14.076492Z","shell.execute_reply.started":"2023-02-23T14:33:14.067114Z","shell.execute_reply":"2023-02-23T14:33:14.075494Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\ndef get_labels(fname):\n    with open(fname,'r') as f:\n        labels = [t.strip() for t in f.read().split(',')]\n    labels2idx = {t:i for i,t in enumerate(labels)}\n    idx2labels = {i:t for i,t in enumerate(labels)}\n    return labels,labels2idx,idx2labels\n\nclass PlanetData(Dataset):\n\n    def __init__(self, csv_file, root_dir, labels_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.labels, self.labels2idx, self.idx2labels = get_labels(labels_file)\n        self.n_labels = len(self.labels)\n        self.transform = transform\n\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n        img = Image.open(img_name + '.jpg').convert('RGB')\n        labels = self.data.iloc[idx, 1]\n        target = torch.zeros(self.n_labels)\n        label_idx = torch.LongTensor([self.labels2idx[tag] for tag in labels.split(' ')])\n        target[label_idx] = 1\n        if self.transform:\n            img = self.transform(img)\n        return img, target","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:14.078487Z","iopub.execute_input":"2023-02-23T14:33:14.079276Z","iopub.status.idle":"2023-02-23T14:33:14.091078Z","shell.execute_reply.started":"2023-02-23T14:33:14.079238Z","shell.execute_reply":"2023-02-23T14:33:14.090034Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class RandomVerticalFlip(object):\n    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL.Image): Image to be flipped.\n        Returns:\n            PIL.Image: Randomly flipped image.\n        \"\"\"\n        if np.random.random() < 0.5:\n            return img.transpose(Image.FLIP_TOP_BOTTOM)\n        return img\n\nclass RandomRotation(object):\n    \"\"\"Rotate PIL.Image randomly (90/180/270 degrees)with a probability of 0.5.\"\"\"\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL.Image): Image to be rotated.\n        Returns:\n            PIL.Image: Randomly rotated image.\n        \"\"\"\n        if np.random.random() < 0.5:\n            deg = np.random.randint(1,3)*90.\n            return img.rotate(deg)\n        return img\n\nclass RandomTranslation(object):\n    \"\"\"Translates PIL.Image randomly (0-10 pixels) with a probability of 0.5.\"\"\"\n\n    def __init__(self,max_vshift=10, max_hshift=10):\n        self.max_vshift = max_vshift\n        self.max_hshift = max_hshift\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL.Image): Image to be translated.\n        Returns:\n            PIL.Image: Randomly translated image.\n        \"\"\"\n        if np.random.random() < 0.5:\n            hshift = np.random.randint(-self.max_hshift,self.max_hshift)\n            vshift = np.random.randint(-self.max_vshift,self.max_vshift)\n            return img.transform(img.size, Image.AFFINE, (1, 0, hshift, 0, 1, vshift))\n        return img","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:14.092343Z","iopub.execute_input":"2023-02-23T14:33:14.092730Z","iopub.status.idle":"2023-02-23T14:33:14.108011Z","shell.execute_reply.started":"2023-02-23T14:33:14.092693Z","shell.execute_reply":"2023-02-23T14:33:14.106980Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\n\ntrain_transforms = transforms.Compose([transforms.RandomCrop(224),\n                        transforms.RandomHorizontalFlip(),\n                        RandomRotation(),\n                        RandomTranslation(),\n                        RandomVerticalFlip(),\n                        transforms.ToTensor()])\ntrainset = PlanetData('/kaggle/input/planets-dt/train_set_norm.csv', '/kaggle/input/planets-dataset/planet/planet/train-jpg',\n                '/kaggle/input/planets-dt/labels.txt', train_transforms)\ntrain_loader = DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:14.121757Z","iopub.execute_input":"2023-02-23T14:33:14.122797Z","iopub.status.idle":"2023-02-23T14:33:14.209467Z","shell.execute_reply.started":"2023-02-23T14:33:14.122755Z","shell.execute_reply":"2023-02-23T14:33:14.208402Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# loop over our epochs\nfor e in range(0, EPOCHS):\n    # set the model in training mode\n    model_nn.train()\n    # initialize the total training and validation loss\n    totalTrainLoss = 0\n    train_losses = []\n    preds = []\n    ys = []\n    totalValLoss = 0\n    # initialize the number of correct predictions in the training\n    # and validation step\n    # loop over the training set\n    for i, (x,y) in enumerate(train_loader):\n        # send the input to the device\n        ys.append(y)\n        (x, y) = (x.to(device), y.to(device))\n        print(i) \n        # perform a forward pass and calculate the training loss\n        pred = model_nn(x)\n        preds.append(pred)\n        loss = lossFn(pred, y)\n        # zero out the gradients, perform the backpropagation step,\n        # and update the weights\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        # add the loss to the total training loss so far and\n        # calculate the number of correct predictions\n        totalTrainLoss += loss\n        train_losses.append(loss)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:14.211336Z","iopub.execute_input":"2023-02-23T14:33:14.212424Z","iopub.status.idle":"2023-02-23T14:33:15.789641Z","shell.execute_reply.started":"2023-02-23T14:33:14.212382Z","shell.execute_reply":"2023-02-23T14:33:15.788334Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning:\n\nFLIP_TOP_BOTTOM is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_TOP_BOTTOM instead.\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: DeprecationWarning:\n\nAFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n\n","output_type":"stream"},{"name":"stdout","text":"0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1179/81509229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# perform a forward pass and calculate the training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1179/223911146.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"],"ename":"RuntimeError","evalue":"CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(ys, preds))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.791056Z","iopub.status.idle":"2023-02-23T14:33:15.791830Z","shell.execute_reply.started":"2023-02-23T14:33:15.791559Z","shell.execute_reply":"2023-02-23T14:33:15.791587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx_data = list(range(0, i))\ny_data = train_losses\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nax.plot(x_data, y_data)\nax.set_xlabel('data trained')\nax.set_ylabel('CrossEntropyLoss')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.793247Z","iopub.status.idle":"2023-02-23T14:33:15.794003Z","shell.execute_reply.started":"2023-02-23T14:33:15.793739Z","shell.execute_reply":"2023-02-23T14:33:15.793764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating The Model Using The Test Data","metadata":{}},{"cell_type":"code","source":"# Read the sample submission CSV file and store it in a DataFrame\ndf_samplesub = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n\n# The DataFrame 'df_samplesub' now contains the data from the sample submission CSV file\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.795441Z","iopub.status.idle":"2023-02-23T14:33:15.796185Z","shell.execute_reply.started":"2023-02-23T14:33:15.795917Z","shell.execute_reply":"2023-02-23T14:33:15.795942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create two separate DataFrames for the test and additional test files\n\n# The first DataFrame will contain the labels for the test-jpg files\ntest = df_samplesub[0 : 40669]\n\n# The second DataFrame will contain the labels for the test-jpg-additional files\nfiles = df_samplesub[40669 : ]\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.797577Z","iopub.status.idle":"2023-02-23T14:33:15.798323Z","shell.execute_reply.started":"2023-02-23T14:33:15.798052Z","shell.execute_reply":"2023-02-23T14:33:15.798077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the test images\n\n# Initialize an empty list to store the images\ntest_img = []\n\n# Loop through the test DataFrame\nfor image_name, tags in tqdm(test.values, miniters=1000):\n    # Read the image file\n    arr = cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(image_name))\n    # Resize the image to (64, 64)\n    test_img.append(cv2.resize(arr, (64, 64)))\n\n# Loop through the additional test files DataFrame\nfor image_name, tags in tqdm(files.values, miniters=1000):\n    # Read the image file\n    arr = cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(image_name))\n    # Resize the image to (64, 64)\n    test_img.append(cv2.resize(arr, (64, 64)))\n\n# Convert the list of images to a numpy array and normalize the pixel values\ntest_img = np.array(test_img, np.float16)/255.0\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.799710Z","iopub.status.idle":"2023-02-23T14:33:15.800470Z","shell.execute_reply.started":"2023-02-23T14:33:15.800174Z","shell.execute_reply":"2023-02-23T14:33:15.800204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up some memory that is not being used by the program.. again\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.801824Z","iopub.status.idle":"2023-02-23T14:33:15.802579Z","shell.execute_reply.started":"2023-02-23T14:33:15.802300Z","shell.execute_reply":"2023-02-23T14:33:15.802325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running the predictions\n\n# Initialize an empty list to store the predictions\nyres = []\n\n# Make predictions on the test images using the model\npredictions = model.predict(test_img, batch_size = 64, verbose = 2)\n\n# Append the predictions to the yres list\nyres.append(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.803932Z","iopub.status.idle":"2023-02-23T14:33:15.804684Z","shell.execute_reply.started":"2023-02-23T14:33:15.804421Z","shell.execute_reply":"2023-02-23T14:33:15.804446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up some memory that is not being used by the program.. again again\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.806006Z","iopub.status.idle":"2023-02-23T14:33:15.806744Z","shell.execute_reply.started":"2023-02-23T14:33:15.806478Z","shell.execute_reply":"2023-02-23T14:33:15.806502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the encoded labels back to their original form\n\n# Initialize an empty array to store the decoded labels\nsub = np.array(yres[0])\n\n# Loop through the encoded labels\nfor i in range (1, len(yres)):\n    # Add the encoded label to the array\n    sub += np.array(yres[i])\n\n# Convert the array to a DataFrame\nsub = pd.DataFrame(sub, columns = label_map)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T14:33:15.808170Z","iopub.status.idle":"2023-02-23T14:33:15.808908Z","shell.execute_reply.started":"2023-02-23T14:33:15.808643Z","shell.execute_reply":"2023-02-23T14:33:15.808668Z"},"trusted":true},"execution_count":null,"outputs":[]}]}